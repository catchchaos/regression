{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "relevant-concentrate",
   "metadata": {},
   "source": [
    "# The different pictures of linear least squares\n",
    "When presented with a set of points and asked to fit a line through it, we typically start by defining a linear model with some parameters. For example, with a 1-dimensional input, the familiar equation *y = m x + c* is a suitable model where the slope *m* and y-intercept *c* are parameters that need to be estimated. Given a new input *xₙ*, the model with optimal parameters allows us to make a reasonable prediction *yₙ*.\n",
    "\n",
    "Let's look at a concrete example from the first recorded application of linear (in the parameters) least squares [2]. In the late eighteenth-century, mathematicians were busy trying to fit a model to capture the variation in the Earth's curvature with increasing latitude. They hypothesized that the length Δ*s* of an arc Δ*λ* of a meridian at the geodetic latitude *λ* takes the form"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extended-microwave",
   "metadata": {},
   "source": [
    "<!-- $$\\frac{\\Delta s}{\\Delta \\lambda} = c_0 + c_1 \\sin^2{\\lambda}$$ . -->\n",
    "![eq:geodetic](latex_images/geodetic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elder-knitting",
   "metadata": {},
   "source": [
    "Notice that the function is not linear in inputs due to the sin² term but continues to be *linear in the parameters*. Their work used data from a series of French surveys conducted a few years earlier in far-off places, with samples ranging from the equatorial to the arctic regions. Here is a table detailing some of the locations, along with a regular 2D plot.\n",
    "\n",
    "<!-- | ID    | Location     | Latitude $\\lambda$ | $\\Delta s/\\Delta \\lambda$ |\n",
    "| :---: | :---:        | :---:              | :---:                     |\n",
    "| 1     | Peru         | 0                  | 25538.85                  |\n",
    "| 2     | Good Hope    | 37.0093            | 25666.65                  |\n",
    "| 3     | Pennsylvania | 43.5556            | 25599.6                   |\n",
    "| 4     | Italy        | 47.7963            | 25640.55                  |\n",
    "| 5     | France       | 51.3327            | 25658.28                  |\n",
    "| 6     | Austria      | 53.0926            | 25683.3                   |\n",
    "| 7     | Lapland      | 73.7037            | 25832.25                  |\n",
    " -->\n",
    "\n",
    "![fig:geodetic data](images/data.jpeg)\n",
    "\n",
    "Data collected in French surveys [1] in the early 1700s. All lengths are reported in double toises (1/0.256537 m) and angles in gradians (2π/400). The relationship is not strictly linear, but we will perform linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civilian-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from plot_utils import *\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# x, y, _, labels = get_linear_system('survey_data')\n",
    "\n",
    "# _, ax = plt.subplots()\n",
    "# ax.scatter(x, y, color='g');\n",
    "# for loc, x_i, y_i in zip(labels, x, y):\n",
    "#     ax.annotate(loc, (x_i, y_i + 6), ha='center', va='bottom')\n",
    "\n",
    "# labels_2d(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exposed-wholesale",
   "metadata": {},
   "source": [
    "Linear regression aims to estimate the parameters of a linear model with the help of such training data. The canonical approach to regression is to compute and minimize an error between model predictions and ground truths.  A popular choice is the sum of all the squared differences, and although this isn't the only viable error function, it is the most popular one and we will use the sum of squared errors throughout this article. This encompasses the set of approximate methods called *linear least squares*. We will see how different branches of mathematics approach the problem using vastly different pictures.\n",
    "\n",
    "## Calculus picture\n",
    "The geodetic model has only two parameters *c₀* and *c₁*. Representing each data point in the training data as *(xᵢ,yᵢ)* where *i* is the row index from the table above, high-school calculus yields optimal values for the parameters. This is done by differentiating the error w.r.t. each parameter and equating to 0. The resulting system of simultaneous equations contains as many equations as parameters and is solved using Gaussian elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-concert",
   "metadata": {},
   "source": [
    "<!-- $$\\mathcal{L} = \\sum_{i=1}^{n} (y_i - \\hat{y}_i )^2 = \\sum_{i=1}^{n} (y_i - (c_0 + c_1 x_i))^2$$\n",
    "$$\\hat{c}_0 = \\underset{c_0}{\\mathrm{arg\\,min}}\\,\\mathcal{L} = \\bar{y} - \\hat{c}_1 \\bar{x}\\,; \\quad \\hat{c}_1 = \\underset{c_1}{\\mathrm{arg\\,min}}\\,\\mathcal{L} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x}) (y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}\\,.$$ -->\n",
    "![eq:calculus_least_squares](latex_images/calculus_LS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-charity",
   "metadata": {},
   "source": [
    "This is actually the ordinary least squares (OLS) approximation for the linear system. As we will see, other approximations also exist. For simple low-dimensional systems, we can visualize the surface of the error function. It might not look like the minimum is unique but I ask you to trust the math!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "southwest-proposition",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from plot_utils import *\n",
    "\n",
    "x, y, _, _ = get_linear_system('survey_data')\n",
    "c_0 = np.linspace(25000, 26000)\n",
    "c_1 = np.linspace(-1000, 1000)\n",
    "c_0_xx, c_1_yy = np.meshgrid(c_0, c_1)\n",
    "\n",
    "errs = y[np.newaxis, np.newaxis, :] - c_0_xx[..., np.newaxis] - c_1_yy[..., np.newaxis]*x[np.newaxis, np.newaxis, :]\n",
    "sum_sq_errs = np.sum(errs**2, axis=-1)\n",
    "ax = plt.subplot(projection='3d')\n",
    "ax.plot_surface(c_0_xx, c_1_yy, sum_sq_errs, alpha=0.5)\n",
    "\n",
    "# Ordinary least squares\n",
    "x_bar, y_bar = x.mean(), y.mean()\n",
    "c_1_ols = ((x - x_bar) * (y - y_bar)).sum() \\\n",
    "          / ((x - x_bar)**2).sum()\n",
    "c_0_ols = y_bar - c_1_ols * x_bar\n",
    "c_ols = [c_0_ols, c_1_ols, np.sum((y - c_0_ols[..., np.newaxis] - c_1_ols*x)**2)]\n",
    "ax.scatter(*c_ols, color='r', marker='x')\n",
    "c_ols[2] -= 1000\n",
    "ax.text(*c_ols, 'Minima', va='top')\n",
    "ax.set_xticks([]), ax.set_yticks([]), ax.set_zticks([])\n",
    "\n",
    "save_animation(ax, 'images/loss.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prerequisite-large",
   "metadata": {},
   "source": [
    "![fig:loss](images/loss.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-execution",
   "metadata": {},
   "source": [
    "### Weighted least squares\n",
    "The different data points may not be equally reliable, and we may have evidence to believe that some errors in the sum should be weighted more than others. By ignoring such additional information, we end up with sub-optimal approximations that are strongly affected by outliers. In the example presented above, perhaps the surveyors admitted that collecting accurate data proved challenging in some regions, such as the equatorial rainforests in Peru or the Cape Peninsula. In Lapland, perhaps heavy snow posed great difficulties resulting in a worse measurement. Armed with this additional information, we replace the error function with a weighted sum of the squared errors and proceed with partial differentiation as earlier. The least squares approximation needs a small modification, resulting in the weighted least squares (WLS) solution. You should try to derive the formula yourself. Let's use weights of 0.25 for the snow affected Lapland region, 0.5 for the slightly errenous measurements, and stick to 1 for the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "irish-dividend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25516.26039871393 282.79566187844523\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y, w, labels = get_linear_system('survey_data')\n",
    "\n",
    "# Ordinary least squares\n",
    "x_bar, y_bar = x.mean(), y.mean()\n",
    "c_1_ols = ((x - x_bar) * (y - y_bar)).sum() \\\n",
    "          / ((x - x_bar)**2).sum()\n",
    "c_0_ols = y_bar - c_1_ols * x_bar\n",
    "print(c_0_ols, c_1_ols)\n",
    "\n",
    "# Weighted least squares\n",
    "x_w_bar, y_w_bar = (w * x).sum() / w.sum(), (w * y).sum() / w.sum()\n",
    "c_1_wls = (w * (x - x_w_bar) * (y - y_w_bar)).sum() \\\n",
    "          / (w * (x - x_w_bar)**2).sum()\n",
    "c_0_wls = y_w_bar - c_1_ols * x_w_bar\n",
    "\n",
    "x_continuous = np.linspace(0, 1)\n",
    "y_ols = c_0_ols + c_1_ols * x_continuous\n",
    "y_wls = c_0_wls + c_1_wls * x_continuous\n",
    "\n",
    "_, ax = plt.subplots()\n",
    "ax.plot(x_continuous, y_ols, '--', label='OLS')\n",
    "ax.plot(x_continuous, y_wls, '--', label='WLS')\n",
    "ax.scatter(x, y, color='g');\n",
    "for loc, x_i, y_i in zip(labels, x, y):\n",
    "    ax.annotate(loc, (x_i, y_i + 6), ha='center', va='bottom')\n",
    "\n",
    "labels_2d(ax, legend=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-requirement",
   "metadata": {},
   "source": [
    "## Linear algebra picture\n",
    "Moving on to multiple input parameters, it becomes imperative to work with vectors and matrices. You can continue with the same picture and use multivariable calculus, but some people prefer a different, geometric view - the linear algebra picture. Let's represent our linear system of *k* input features and *n* equations using vector-matrix notation (with bold capital letters representing matrices and bold small letters representing vectors): **Xc = y**, or"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nervous-lancaster",
   "metadata": {},
   "source": [
    "<!-- $$\\begin{bmatrix}\n",
    "x_{11} & x_{12} & \\dots  & x_{1k} \\\\\n",
    "x_{21} & x_{22} & \\dots  & x_{2k} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "x_{n1} & x_{n2} & \\dots  & x_{nk} \\\\\n",
    "\\end{bmatrix} \\cdot\n",
    "\\begin{bmatrix} c_{0} \\\\ c_{1} \\\\ \\vdots \\\\ c_{k} \\end{bmatrix} =\n",
    "\\begin{bmatrix} y_{1} \\\\ y_{2} \\\\ \\vdots \\\\ y_{n} \\end{bmatrix}\\,.$$ -->\n",
    "![eq:Xc=y](latex_images/linear_system.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "industrial-merchant",
   "metadata": {},
   "source": [
    "In his [18-06](https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/) linear algebra course, Gilbert Strang introduces the column space picture of matrix multiplication and postulates that solving any linear system is equivalent to finding coefficients to express **y** as a linear combination or weighted average of the columns of **X**. The problem with real-world overconstrained systems is that **y** lies outside the column space of **X** i.e. no linear combination of the columns of **X** exactly yield **y**. The least squares solution is simply the projection of the vector **y** onto the subspace spanned by the columns of ***X***. Intuitively, this projection **ŷ** is the vector in the column space that is *closest* (according to some measure of error) to **y**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "terminal-editing",
   "metadata": {},
   "source": [
    "Unfortunately, the only way modest 3-dimensional beings like us can visualize this is by considering a trivial system consisting of three equations with two parameters. Let's use Peru, Italy, and Lapland from the table and look at the output vector, along with its projection on the column space. Additionally, to better see the picture, we will change the output vector slightly and consider a system of unit vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "pacific-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "X, y, _, labels = get_filtered_linear_system('survey_data')\n",
    "\n",
    "# Normal to the column space plane\n",
    "normal = np.cross(X[:,0], X[:,1])\n",
    "xx, yy = np.meshgrid(np.linspace(-.2, 1), np.linspace(-.2, 1))\n",
    "z = (-normal[0]*xx -normal[1]*yy) / normal[2]\n",
    "\n",
    "# Project y to the subspace\n",
    "y_hat = X @ np.linalg.inv(X.transpose() @ X) @ X.transpose() @ y\n",
    "\n",
    "ax = plt.subplot(projection='3d')\n",
    "ax.quiver(*np.zeros(3), *X[:,0], arrow_length_ratio=0.1)\n",
    "ax.quiver(*np.zeros(3), *X[:,1], arrow_length_ratio=0.1)\n",
    "ax.quiver(*np.zeros(3), *y, arrow_length_ratio=0.1, color='g')\n",
    "ax.quiver(*np.zeros(3), *y_hat, arrow_length_ratio=0.1, color='c')\n",
    "ax.plot(*[(c1, c2) for c1, c2 in zip(y_hat, y)], color='r', linestyle='--')\n",
    "ax.plot_surface(xx, yy, z, alpha=0.5)\n",
    "\n",
    "ax.text(*y, '$\\mathbf{y}$')\n",
    "ax.text(*y_hat, '$\\mathbf{\\hat{y}}$')\n",
    "ax.text(*X[:,0], '$\\mathbf{x_{\\star 1}}$')\n",
    "ax.text(*X[:,1], '$\\mathbf{x_{\\star 2}}$')\n",
    "\n",
    "labels_3d(ax)\n",
    "# save_animation(ax, 'images/projection.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-finnish",
   "metadata": {},
   "source": [
    "![fig:projection](images/projection.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-tennessee",
   "metadata": {},
   "source": [
    "Since the projection **ŷ** serves as an approximation of **y**, the resulting error is simply the difference between them, **e** = **y** - **ŷ** (red dotted line). In reality, **e** is perpendicular to every vector in the column space of **X** and, to be precise, is a member of its left nullspace. Thus, the inner product ⟨**Xᵀ**,**e**⟩ is the **0** vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-tribe",
   "metadata": {},
   "source": [
    "<!-- $$\\langle \\mathbf{X^T}, \\mathbf{e}\\rangle = \\mathbf{0}$$\n",
    "$$\\mathbf{X^T}(\\mathbf{y} - \\mathbf{\\hat{y}}) = \\mathbf{X^T} (\\mathbf{y} - \\mathbf{X\\hat{c}}_{\\scriptscriptstyle OLS}) = \\mathbf{0}$$\n",
    "$$\\implies \\mathbf{\\hat{c}}_{\\scriptscriptstyle OLS} = (\\mathbf{X^T}\\mathbf{X})^{-1} \\mathbf{X^T} \\mathbf{y}\\,.$$ -->\n",
    "![eq:geometric_ordinary_least_squares](latex_images/la_OLS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approximate-berlin",
   "metadata": {},
   "source": [
    "This is equivalent to the OLS solution obtained earlier. An important step here is the inversion of **XᵀX**, which requires the columns of **X** to be independent. With this picture, both the tractability and the uniqueness of the OLS approximation become evident.\n",
    "\n",
    "## What about weights?\n",
    "Rearranging the weights into a diagonal matrix **W**, the geometric linear algebra picture holds even for the WLS approximation. We replace the inner product from the previous derivation with a weighted inner product [1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative-retention",
   "metadata": {},
   "source": [
    "<!-- $$\\langle \\mathbf{X^T}, \\mathbf{e} \\rangle _\\mathbf{W} = \\mathbf{0}$$\n",
    "$$\\implies \\mathbf{\\hat{c}}_{\\scriptscriptstyle WLS} = (\\mathbf{X^T W X})^\\mathbf{-1} \\mathbf{X^TWy}\\,.$$ -->\n",
    "![eq:geometric_weighted_least_squares](latex_images/la_WLS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-integrity",
   "metadata": {},
   "source": [
    "This expression is a special case of a more general solution called generalized least squares. However, to get a better intuition we need to view the problem through the lens of probability.\n",
    "\n",
    "## Probability picture\n",
    "When dealing with data that contains measurement errors, it is natural to rely on probability theory, a branch of mathematics developed specifically for this purpose. Texts on probabilistic machine learning such as Christopher Bishop's excellent [PRML](https://www.microsoft.com/en-us/research/people/cmbishop/prml-book/) often begin with this view of linear least squares. To produce results consistent with our earlier pictures, we will assume that the error in each data point is a random variable drawn from a zero-mean Gaussian distribution with unknown variance σ. Each observation can be represented as"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "biblical-machinery",
   "metadata": {},
   "source": [
    "<!-- $$y_i = \\mathbf{c x_i^T} + e\\, \\quad \\, \\textrm{where}\\, e \\sim \\mathcal{N}(0, \\sigma)$$\n",
    "$$\\mathrm{or}\\,\\, y_i \\sim \\mathcal{N}(\\mathbf{cx_i^T}, \\sigma)$$\n",
    "$$\\implies p(y_i|\\mathbf{c}, \\mathbf{x_i^T}, \\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp{-\\frac{1}{2}\\left(\\frac{y_i - c_i \\mathbf{x_i^T}}{\\sigma}\\right)^2}\\,.$$ -->\n",
    "![eq:1D gaussian_sample](latex_images/gaussian_1d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-saver",
   "metadata": {},
   "source": [
    "Since σ is constant, assuming each sample is independent and performing maximum likelihood estimation (MLE) produces the familiar expression,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-midnight",
   "metadata": {},
   "source": [
    "<!-- $$\\begin{align}\n",
    "\\mathbf{\\hat{c}}_{\\scriptscriptstyle OLS} &= \\underset{\\mathbf{c}}{\\mathrm{arg\\,max}}\\, \\prod_{i=1}^n p(y_i|\\mathbf{c}, \\mathbf{x_i^T})\\\\\n",
    "&= \\underset{\\mathbf{c}}{\\mathrm{arg\\,min}}\\, \\sum_{i=1}^n(y_i - c_i\\mathbf{x_i^T})^2\\,.\n",
    "\\end{align}\n",
    "$$ -->\n",
    "![eq:maximum likelihood estimation](latex_images/MLE.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-starter",
   "metadata": {},
   "source": [
    "It turns out that computing the Euclidean errors and minimizing the sum of their squares is equivalent to MLE under the assumption of constant Gaussian noise! This is a reasonable assumption for real systems because the error is a byproduct of interference from potentially many different sources as explained in [this post](http://gregorygundersen.com/blog/2019/02/01/clt/). Hence, the *central limit theorem* validates the Gaussian as a suitable model for the additive noise. Different error functions in the calculus derivation correspond to different definitions of the inner product in the linear algebra derivation and different likelihoods in the probability derivation. Papers in computer vision for instance use the absolute difference as an error function, which can be derived under a Laplacian distribution.\n",
    "\n",
    "## Weighted and generalized least squares\n",
    "A natural extension is to look at what happens if each error is no longer restricted to be drawn from the same Gaussian. The samples are still independent but no longer identically distributed and out pops WLS formulation. The probability picture also enables us to reason about the possibility of the errors being correlated. This is the setup for generalized least squares where all the errors are drawn from a k-dimensional multivariate Gaussian with mean 0 and covariance matrix Σ. Proceeding with MLE we end up with the following multivariate minimization,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "printable-vietnamese",
   "metadata": {},
   "source": [
    "<!-- $$\\mathcal{L} = \\frac{1}{\\sqrt{(2\\pi)^k\\Sigma^{-1}}} \\, \\exp\\frac{-1}{2}(\\mathbf{y} - \\mathbf{Xc}) \\mathbf{^T}  \\mathbf{\\Sigma^{-1}} (\\mathbf{y} - \\mathbf{Xc})$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial \\log\\mathcal{L}}{\\partial \\mathbf{c}} &= \\frac{-1}{2} \\cdot 2 \\, (\\mathbf{y} - \\mathbf{Xc}) \\mathbf{^T} \\mathbf{\\Sigma^{-1}} \\cdot \\frac{\\partial (\\mathbf{y} - \\mathbf{Xc})}{\\partial \\mathbf{c}} \\\\\n",
    "&= (\\mathbf{y} - \\mathbf{Xc}) \\mathbf{^T} \\mathbf{\\Sigma^{-1}} \\mathbf{Xc} = \\mathbf{0}\n",
    "\\end{align}\n",
    "$$\\implies \\mathbf{\\hat{c}}_{\\scriptscriptstyle GLS} = (\\mathbf{X^T \\Sigma^{-1} X})^\\mathbf{-1} \\mathbf{X^T \\Sigma^{-1} y}\\,.$$ -->\n",
    "![eq:generalised least squares](latex_images/vector_GLS.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "related-stick",
   "metadata": {},
   "source": [
    "If you find this hard to follow, refer to this [cheat sheet](https://www.math.uwaterloo.ca/~hwolkowi/matrixcookbook.pdf) for multivariate calculus. Notice the similarities between the WLS and GLS solutions. It becomes obvious that the WLS method is a special case of GLS with a diagonal covariance matrix, but no such conditions are necessary for GLS.\n",
    "\n",
    "## Conclusion\n",
    "The simplicity of its setup and formulation makes linear regression an appealing problem for many communities. As a result, a wide range of approaches has been developed over time, often with different pictures. This article compares a few different views of the variants of linear least squares that ultimately produce the same closed-form expressions, albeit with very different pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acknowledged-reaction",
   "metadata": {},
   "source": [
    "[1] Farnebäck, Gunnar. [Polynomial expansion for orientation and motion estimation.](https://www.ida.liu.se/ext/WITAS-ev/Computer_Vision_Technologies/PaperInfo/farneback02.html) (2002), Linköping University, Sweden\n",
    "\n",
    "[2] Nievergelt, Yves. [A tutorial history of least squares with applications to astronomy and geodesy.](https://www.sciencedirect.com/science/article/pii/S0377042700003435) (2001), Numerical Analysis: Historical Developments in the 20th Century"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
